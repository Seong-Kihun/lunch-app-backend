# ğŸš€ ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„ ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” ëŸ°ì¹˜ ì•±ì˜ ê³ ê¸‰ ê¸°ëŠ¥ë“¤ì„ êµ¬í˜„í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“‹ êµ¬í˜„ëœ ê³ ê¸‰ ê¸°ëŠ¥ë“¤

### 1. Redis ìºì‹± ì‹œìŠ¤í…œ ğŸ—„ï¸
- **ëª©ì **: ì‘ë‹µ ì‹œê°„ ë‹¨ì¶• ë° ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ ê°ì†Œ
- **íŒŒì¼**: `redis_cache.py`
- **ì£¼ìš” ê¸°ëŠ¥**:
  - ìë™ ìºì‹±/ìºì‹œ ë¬´íš¨í™”
  - ì‚¬ìš©ìë³„ ìºì‹±
  - íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ì •ë¦¬
  - ì„±ëŠ¥ í†µê³„ ëª¨ë‹ˆí„°ë§

### 2. Celery ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ ğŸ”„
- **ëª©ì **: ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¬´ê±°ìš´ ì‘ì—… ì²˜ë¦¬
- **íŒŒì¼**: `celery_tasks.py`
- **ì£¼ìš” ê¸°ëŠ¥**:
  - ì¶”ì²œ ê·¸ë£¹ ìºì‹œ ìƒì„±
  - ì‚¬ìš©ì ë¶„ì„ ë°ì´í„° ì²˜ë¦¬
  - ë§Œë£Œëœ ë°ì´í„° ì •ë¦¬
  - ëŒ€ëŸ‰ ì•Œë¦¼ ì „ì†¡
  - ì •ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ë§

### 3. ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© ì‹œìŠ¤í…œ ğŸ—ƒï¸
- **ëª©ì **: ìˆ˜í‰ í™•ì¥ì„± í™•ë³´
- **íŒŒì¼**: `database_sharding.py`
- **ì£¼ìš” ê¸°ëŠ¥**:
  - í•´ì‹œ ê¸°ë°˜ ìƒ¤ë“œ ë¶„ì‚°
  - ìƒ¤ë“œë³„ ë°ì´í„° ê´€ë¦¬
  - í¬ë¡œìŠ¤ ìƒ¤ë“œ ê²€ìƒ‰
  - ìƒ¤ë“œ ì¬ê· í˜•í™”

### 4. ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ğŸ—ï¸
- **ëª©ì **: ëª¨ë“ˆë³„ ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤ ë¶„ë¦¬
- **ë””ë ‰í† ë¦¬**: `microservices/`
- **êµ¬í˜„ëœ ì„œë¹„ìŠ¤**:
  - ì‚¬ìš©ì ê´€ë¦¬ ì„œë¹„ìŠ¤ (í¬íŠ¸ 5001)
  - íŒŒí‹° ê´€ë¦¬ ì„œë¹„ìŠ¤ (í¬íŠ¸ 5002)
  - ì¶”ì²œ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤ (í¬íŠ¸ 5003)

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 1. í™˜ê²½ ì„¤ì •

#### í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

#### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„±
export REDIS_URL=redis://localhost:6379/0
export CELERY_BROKER_URL=redis://localhost:6379/1
export CELERY_RESULT_BACKEND=redis://localhost:6379/2
export SECRET_KEY=your-secret-key-here
```

### 2. Redis ì„œë²„ ì‹œì‘
```bash
# Redis ì„œë²„ ì‹œì‘
redis-server

# ë˜ëŠ” Docker ì‚¬ìš©
docker run -d -p 6379:6379 redis:7-alpine
```

### 3. Celery ì›Œì»¤ ì‹œì‘
```bash
# í„°ë¯¸ë„ 1: Celery ì›Œì»¤
celery -A celery_tasks worker --loglevel=info

# í„°ë¯¸ë„ 2: Celery Beat (ì •ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬)
celery -A celery_tasks beat --loglevel=info
```

### 4. ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì‹œì‘
```bash
# í„°ë¯¸ë„ 3: ì‚¬ìš©ì ì„œë¹„ìŠ¤
python microservices/user_service.py

# í„°ë¯¸ë„ 4: íŒŒí‹° ì„œë¹„ìŠ¤
python microservices/party_service.py

# í„°ë¯¸ë„ 5: ì¶”ì²œ ì„œë¹„ìŠ¤
python microservices/recommendation_service.py
```

### 5. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘
```bash
# í„°ë¯¸ë„ 6: ë©”ì¸ Flask ì•±
python lunch_app/app.py
```

## ğŸ³ Docker Composeë¡œ í•œ ë²ˆì— ì‹¤í–‰

### ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰
```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸ í™•ì¸
docker-compose logs -f main_app
docker-compose logs -f celery_worker
docker-compose logs -f user_service
```

### ì„œë¹„ìŠ¤ë³„ ìƒíƒœ í™•ì¸
```bash
# ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ í™•ì¸
docker-compose ps

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose exec redis redis-cli ping
docker-compose exec main_app curl http://localhost:5000/health
docker-compose exec user_service curl http://localhost:5001/health
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬

### Redis ëª¨ë‹ˆí„°ë§
```bash
# Redis CLI ì ‘ì†
redis-cli

# í†µê³„ ì •ë³´ í™•ì¸
INFO

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
INFO memory

# í‚¤ ê°œìˆ˜ í™•ì¸
DBSIZE
```

### Celery ëª¨ë‹ˆí„°ë§
```bash
# ì‘ì—… ìƒíƒœ í™•ì¸
celery -A celery_tasks inspect active

# ì›Œì»¤ ìƒíƒœ í™•ì¸
celery -A celery_tasks inspect stats

# ì •ê¸° ì‘ì—… í™•ì¸
celery -A celery_tasks inspect scheduled
```

### ìƒ¤ë”© ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§
```python
from database_sharding import get_shard_stats

# ìƒ¤ë“œë³„ í†µê³„ í™•ì¸
stats = get_shard_stats()
print(f"ìƒ¤ë“œ í†µê³„: {stats}")

# ìƒ¤ë“œ ì¬ê· í˜•í™” ê³„íš í™•ì¸
from database_sharding import sharding_system
rebalance_plan = sharding_system.rebalance_shards()
print(f"ì¬ê· í˜•í™” ê³„íš: {rebalance_plan}")
```

## ğŸ”§ API ì‚¬ìš© ì˜ˆì‹œ

### Redis ìºì‹± ì‚¬ìš©
```python
from redis_cache import redis_cache, cache_result, cache_user_result

# ì§ì ‘ ìºì‹±
redis_cache.set("user:profile:123", user_data, expire=3600)
cached_data = redis_cache.get("user:profile:123")

# ë°ì½”ë ˆì´í„°ë¡œ ìë™ ìºì‹±
@cache_result(expire=1800)
def get_expensive_data():
    # ë¬´ê±°ìš´ ê³„ì‚° ì‘ì—…
    return calculated_data

@cache_user_result(expire=3600)
def get_user_profile(user_id):
    # ì‚¬ìš©ìë³„ë¡œ ìºì‹±
    return user_profile_data
```

### Celery ì‘ì—… ì‹¤í–‰
```python
from celery_tasks import (
    generate_recommendation_cache_async,
    process_user_analytics_async,
    cleanup_expired_data_async
)

# ë¹„ë™ê¸° ì‘ì—… ì‹¤í–‰
task = generate_recommendation_cache_async.delay()
print(f"ì‘ì—… ID: {task.id}")

# ì‘ì—… ìƒíƒœ í™•ì¸
from celery_tasks import get_task_status
status = get_task_status(task.id)
print(f"ì‘ì—… ìƒíƒœ: {status}")
```

### ìƒ¤ë”© ì‹œìŠ¤í…œ ì‚¬ìš©
```python
from database_sharding import (
    get_user_shard,
    get_user_data_sharded,
    create_user_sharded,
    search_users_sharded
)

# ì‚¬ìš©ì ìƒ¤ë“œ í™•ì¸
shard_id = get_user_shard("KOICA001")
print(f"ì‚¬ìš©ì KOICA001ì€ ìƒ¤ë“œ {shard_id}ì— ìœ„ì¹˜")

# ìƒ¤ë”©ëœ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ì ìƒì„±
user_data = {
    'employee_id': 'KOICA999',
    'nickname': 'ìƒˆì‚¬ìš©ì',
    'gender': 'ë‚¨',
    'age_group': '20ëŒ€',
    'main_dish_genre': 'í•œì‹,ë¶„ì‹'
}
success = create_user_sharded(user_data)

# í¬ë¡œìŠ¤ ìƒ¤ë“œ ê²€ìƒ‰
search_results = search_users_sharded('í•œì‹', limit=10)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### Redis ì—°ê²° í…ŒìŠ¤íŠ¸
```bash
python redis_cache.py
```

### Celery ì‘ì—… í…ŒìŠ¤íŠ¸
```bash
python celery_tasks.py
```

### ìƒ¤ë”© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
```bash
python database_sharding.py
```

### ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
```bash
# ì‚¬ìš©ì ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:5001/users \
  -H "Content-Type: application/json" \
  -d '{"employee_id":"TEST001","nickname":"í…ŒìŠ¤íŠ¸ì‚¬ìš©ì"}'

# ì‚¬ìš©ì ì¡°íšŒ í…ŒìŠ¤íŠ¸
curl http://localhost:5001/users/TEST001
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. Redis ìºì‹± ìµœì í™”
- ì ì ˆí•œ TTL ì„¤ì • (ë„ˆë¬´ ì§§ìœ¼ë©´ ìºì‹œ ë¯¸ìŠ¤, ë„ˆë¬´ ê¸¸ë©´ ë©”ëª¨ë¦¬ ë‚­ë¹„)
- íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”ë¡œ ì¼ê´€ì„± ìœ ì§€
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

### 2. Celery ìµœì í™”
- ì›Œì»¤ ìˆ˜ë¥¼ CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •
- ì‘ì—… í ë¶„ë¦¬ (ìš°ì„ ìˆœìœ„ë³„)
- ì‘ì—… íƒ€ì„ì•„ì›ƒ ì„¤ì •

### 3. ìƒ¤ë”© ìµœì í™”
- ìƒ¤ë“œ ê°œìˆ˜ë¥¼ ë°ì´í„° í¬ê¸°ì— ë§ê²Œ ì¡°ì •
- ìƒ¤ë“œë³„ ì¸ë±ìŠ¤ ìµœì í™”
- ì •ê¸°ì ì¸ ìƒ¤ë“œ ì¬ê· í˜•í™”

### 4. ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ìµœì í™”
- ì„œë¹„ìŠ¤ ê°„ í†µì‹  ìµœì†Œí™”
- ì ì ˆí•œ ì„œë¹„ìŠ¤ ë¶„ë¦¬ ê²½ê³„ ì„¤ì •
- ê³µí†µ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê³µìœ 

## ğŸš¨ ë¬¸ì œ í•´ê²°

### Redis ì—°ê²° ì‹¤íŒ¨
```bash
# Redis ì„œë²„ ìƒíƒœ í™•ì¸
redis-cli ping

# í¬íŠ¸ í™•ì¸
netstat -an | grep 6379

# Redis ë¡œê·¸ í™•ì¸
tail -f /var/log/redis/redis-server.log
```

### Celery ì›Œì»¤ ì‹œì‘ ì‹¤íŒ¨
```bash
# Redis ì—°ê²° í™•ì¸
redis-cli ping

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo $CELERY_BROKER_URL

# Celery ì„¤ì • í™•ì¸
celery -A celery_tasks inspect ping
```

### ìƒ¤ë”© ì‹œìŠ¤í…œ ì˜¤ë¥˜
```python
# ìƒ¤ë“œ ì—°ê²° ìƒíƒœ í™•ì¸
from database_sharding import sharding_system
for shard_id in range(sharding_system.shard_count):
    try:
        conn = sharding_system.get_shard_connection(shard_id)
        print(f"ìƒ¤ë“œ {shard_id} ì—°ê²° ì„±ê³µ")
    except Exception as e:
        print(f"ìƒ¤ë“œ {shard_id} ì—°ê²° ì‹¤íŒ¨: {e}")
```

## ğŸ”® í–¥í›„ ê°œì„  ê³„íš

### 1. ê³ ê¸‰ ìºì‹± ì „ëµ
- Redis Cluster êµ¬í˜„
- ìºì‹œ ê³„ì¸µí™” (L1: ë©”ëª¨ë¦¬, L2: Redis, L3: ë°ì´í„°ë² ì´ìŠ¤)
- ì§€ëŠ¥í˜• ìºì‹œ ë¯¸ìŠ¤ ì˜ˆì¸¡

### 2. ê³ ê¸‰ ìƒ¤ë”©
- ë™ì  ìƒ¤ë“œ ì¶”ê°€/ì œê±°
- ìƒ¤ë“œ ê°„ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
- ìƒ¤ë“œë³„ ë°±ì—… ë° ë³µêµ¬

### 3. ì„œë¹„ìŠ¤ ë©”ì‹œ
- Istio ë˜ëŠ” Linkerd ë„ì…
- ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ ìë™í™”
- ì„œí‚· ë¸Œë ˆì´ì»¤ íŒ¨í„´ êµ¬í˜„

### 4. ëª¨ë‹ˆí„°ë§ ê°•í™”
- APM (Application Performance Monitoring) ë„ì…
- ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„
- ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•

## ğŸ“š ì°¸ê³  ìë£Œ

- [Redis ê³µì‹ ë¬¸ì„œ](https://redis.io/documentation)
- [Celery ê³µì‹ ë¬¸ì„œ](https://docs.celeryproject.org/)
- [Flask ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°€ì´ë“œ](https://flask.palletsprojects.com/en/2.3.x/patterns/appfactories/)
- [ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© íŒ¨í„´](https://en.wikipedia.org/wiki/Shard_(database_architecture))
- [Docker Compose ê°€ì´ë“œ](https://docs.docker.com/compose/)

---

ì´ ê°€ì´ë“œë¥¼ í†µí•´ ëŸ°ì¹˜ ì•±ì˜ ê³ ê¸‰ ê¸°ëŠ¥ë“¤ì„ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„í•˜ê³  ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•˜ë©´ ê°œë°œíŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”! ğŸš€
